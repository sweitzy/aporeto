#!/usr/bin/env python3

# problem3: see https://github.com/aporeto-inc/quiz

'''
### Problem3: Go sample:

You will need to implement a program in go as described below:

```bash
gosample [-help|-h]
gosample -urls=<comma-seperated-one-or-more-urls>
```

This binary should be able to read multiple urls and generate a word (a word only contains letters A-Za-z0-9) frequency table. Output can be stored in files with names url1.txt, url2.txt â€¦ in the following format:
```bash
  url: <url>
    word1: count
    word2: count
```

Example:

See samples/problem3/url1.txt

**[Extra Credit]**

Handle URLs in parallel and demonstrate reduced time to process all URLs. Note: You only need to implement serial or parallel but not both.
'''

import sys
import getopt
import requests
import re

def usage():
    print('pysample [-help|-h]')
    print('pysample -urls=<comma-seperated-one-or-more-urls>')

def main():

    try:
        opts, args = getopt.getopt(sys.argv[1:], 'h', ['urls=', 'help'])
    except getopt.GetoptError as err:
        # print help information and exit:
        print(err)  # will print something like 'option -a not recognized'
        usage()
        sys.exit(2)

    urls = None

    # TODO: try argparse instead

    for o, a in opts:
        if o in ('-h', '--help'):
            usage()
            sys.exit()
        elif o == '--urls':
            urls = a 
        else:
            assert False, 'unhandled option'

    if len(args) > 0:
        print('Unwanted args', args)
        usage()
        sys.exit(2)

    if urls is None:
        print('Missing --urls')
        usage()
        sys.exit(2)

    # TODO: for some reason, https://www.aporeto.com returns 403, but curl works!
    url_counter = 1
    for url in urls.split(','):
        print(url_counter, url)
        resp = requests.get(url)
        if resp.status_code != requests.codes.ok:
            raise NameError("Did not get ok response code")
        # process the response using iterator for efficiency
#        for word in re.finditer(r'(\w+)', resp.text):
#            print(word.group(0))
        url_counter += 1

if __name__ == '__main__':
    main()
